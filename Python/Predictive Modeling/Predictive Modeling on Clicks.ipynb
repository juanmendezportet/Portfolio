{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction:\n",
    "\n",
    "In this notebook we'll explore a search engine marketing campaign database and make predictions for the number of Clicks. To make these predictions we'll take into account the features given in the database and also features we engineered ourselves. We'll make the predictions trying out 3 different models (ElasticNet, DecisionTree and NeuralNetworks), to which we will apply HP tuning. From those 3 we'll choose the best model and use it to make predictions on the Kaggle data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part I: Imports and Data Check</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Importing libraries \n",
    "\n",
    "import os\n",
    "import numpy             as np                       # mathematical essentials\n",
    "import pandas            as pd                       # data science essentials\n",
    "import sklearn.linear_model                          # linear models\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split # train/test split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sklearn.tree\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "###Importing data \n",
    "\n",
    "#Reading modeling data into Python\n",
    "modeling_data = './Data/train.csv'\n",
    "\n",
    "#Creating df_train as the train data\n",
    "df_train = pd.read_csv(filepath_or_buffer = modeling_data,\n",
    "                       header     = 0,\n",
    "                       index_col  = 'entry_id')\n",
    "\n",
    "\n",
    "\n",
    "#Reading testing data into Python\n",
    "testing_data = './Data/test.csv'\n",
    "\n",
    "#Creating df_test as the train data\n",
    "df_test = pd.read_csv(filepath_or_buffer = testing_data,\n",
    "                      header     = 0,\n",
    "                      index_col  = 'entry_id')\n",
    "\n",
    "#Creating set feature in both data sets to differentiate test and train data\n",
    "df_train['set'] = 'Not Kaggle'\n",
    "df_test ['set'] = 'Kaggle'\n",
    "\n",
    "#Concatenating datasets together for missing value analysis and feature engineering\n",
    "df_full = pd.concat(objs = [df_train, df_test],\n",
    "                    axis = 0,\n",
    "                    ignore_index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Exploration</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Transforming columns in train_df for Data Exploration\n",
    "\n",
    "#Changing the Impressions column to numeric\n",
    "df_train['Impressions'] = pd.to_numeric(df_train['Impressions'], errors = 'coerce')\n",
    "\n",
    "#Changing the Avg. Cost per Click column to numeric and removing special characters\n",
    "df_train['Avg. Cost per Click'] = pd.to_numeric(df_train['Avg. Cost per Click'].replace('[\\$,]', '', regex = True), errors = 'coerce')\n",
    "\n",
    "#Changing the Search Engine Bid column to numeric and removing special characters\n",
    "df_train['Search Engine Bid'] = pd.to_numeric(df_train['Search Engine Bid'].replace('[\\$,]', '', regex = True), errors = 'coerce')\n",
    "\n",
    "#Chaning the Clicks column to numeric\n",
    "df_train['Clicks'] = pd.to_numeric(df_train['Clicks'], errors = 'coerce')\n",
    "\n",
    "#Defining the LabelEncoder function\n",
    "le = LabelEncoder()\n",
    "\n",
    "#Encoding the Publisher Name column\n",
    "df_train['Publisher_encoded'] = le.fit_transform(df_train['Publisher Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Creating a plot to see the distribution of the Clicks column\n",
    "\n",
    "#Filtering to only see the data in the range of 1 - 20 clicks\n",
    "filtered_clicks = df_train['Clicks'][(df_train['Clicks'] >= 1) & (df_train['Clicks'] <= 20)]\n",
    "\n",
    "#Plotting the histogram for clicks in the range of 1 - 20\n",
    "plt.figure(figsize = (10, 6))\n",
    "plt.hist(filtered_clicks, bins = 20, range = (1,21), color = 'skyblue', edgecolor = 'white', align = 'left')\n",
    "\n",
    "#Adding title, label, ticks and a grid to the plot\n",
    "plt.title('Histogram of Clicks')\n",
    "plt.xlabel('Number of Clicks')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(range(1, 21))  \n",
    "plt.grid(axis = 'y', alpha = 0.75)\n",
    "\n",
    "#Showing the plot\n",
    "plt.show()\n",
    "\n",
    "###Creating a plot to see the avg Clicks per Impressions bin\n",
    "\n",
    "#Creating bins to divide the values in the impressions column by percentile \n",
    "bins = df_train['Impressions'].quantile([0, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 1.0]).tolist()\n",
    "df_train['Impression_Bins'] = pd.cut(df_train['Impressions'], bins, labels = range(1,11))\n",
    "\n",
    "#Calculating the avg Clicks per bin\n",
    "clicks_per_bin = df_train.groupby('Impression_Bins')['Clicks'].mean()\n",
    "\n",
    "#Creating the bar plot\n",
    "clicks_per_bin.plot(kind = 'bar', color = 'skyblue', edgecolor = 'white')\n",
    "\n",
    "#Adding title, label and ticks to the plot\n",
    "plt.title('Average Clicks per Impression Bin')\n",
    "plt.xlabel('Impression Bin')\n",
    "plt.ylabel('Average Clicks')\n",
    "plt.xticks(rotation = 0)  \n",
    "\n",
    "#Showing the plot\n",
    "plt.show()\n",
    "\n",
    "###Creating a plot to see the avg Clicks per 'Avg. Cost per Click' bin\n",
    "\n",
    "#Creating bins to divide the values in the 'Avg. Cost per Click' column by percentile \n",
    "bins_2 = df_train['Avg. Cost per Click'].quantile([0, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 1.0]).tolist()\n",
    "df_train['Avg_CPC_Bins'] = pd.cut(df_train['Avg. Cost per Click'], bins_2, labels = range(1, 11))\n",
    "\n",
    "#Calculating the avg Clicks per bin\n",
    "clicks_per_avg_cpc_bin = df_train.groupby('Avg_CPC_Bins')['Clicks'].mean()\n",
    "\n",
    "#Creating the bar plot\n",
    "clicks_per_avg_cpc_bin.plot(kind = 'bar', color = 'skyblue', edgecolor = 'white')\n",
    "\n",
    "#Adding title, label and ticks to the plot\n",
    "plt.title('Average Clicks per Avg. CPC Bin')\n",
    "plt.xlabel('Avg. CPC Bin')\n",
    "plt.ylabel('Average Clicks')\n",
    "plt.xticks(rotation = 0)\n",
    "\n",
    "#Showing the plot\n",
    "plt.show()\n",
    "\n",
    "###Creating a plot to see the avg Clicks per 'Search Engine Bid' bin\n",
    "\n",
    "#Creating bins to divide the values in the 'Search Engine Bid' column\n",
    "bins_3 = np.linspace(df_train['Search Engine Bid'].min(), df_train['Search Engine Bid'].max(), 11)\n",
    "df_train['Search_Bid_Bins'] = pd.cut(df_train['Search Engine Bid'], bins_3, labels = range(1, 11))\n",
    "\n",
    "#Calculating the avg Clicks per bin\n",
    "clicks_per_search_bid_bin = df_train.groupby('Search_Bid_Bins')['Clicks'].mean()\n",
    "\n",
    "#Creating the bar plot\n",
    "clicks_per_search_bid_bin.plot(kind = 'bar', color = 'skyblue', edgecolor = 'white')\n",
    "\n",
    "#Adding title, label and ticks to the plot\n",
    "plt.title('Average Clicks per Search Engine Bid Bin')\n",
    "plt.xlabel('Search Engine Bid Bin')\n",
    "plt.ylabel('Average Clicks')\n",
    "plt.xticks(rotation = 0)\n",
    "\n",
    "#Showing the plot\n",
    "plt.show()\n",
    "\n",
    "###Creating a plot to see the avg Clicks per 'Publisher Name' \n",
    "\n",
    "#Calculating the avg Clicks per publisher\n",
    "clicks_per_publisher = df_train.groupby('Publisher_encoded')['Clicks'].mean()\n",
    "\n",
    "#Creating the bar plot\n",
    "clicks_per_publisher.plot(kind = 'bar', color = 'skyblue', edgecolor = 'white')\n",
    "\n",
    "#Adding title, label and ticks to the plot\n",
    "plt.title('Average Clicks per publisher')\n",
    "plt.xlabel('Publishers')\n",
    "plt.ylabel('Average Clicks')\n",
    "plt.xticks(rotation = 0)  \n",
    "\n",
    "#Showing the plot\n",
    "plt.show()\n",
    "\n",
    "###Creating a plot to see the avg Clicks per 'Publisher Name'\n",
    "\n",
    "#Calculating the avg Clicks per Campaign\n",
    "average_clicks_by_campaign = df_train.groupby('Campaign')['Clicks'].mean()\n",
    "\n",
    "#Sorting the results\n",
    "sorted_avg_clicks_by_campaign = average_clicks_by_campaign.sort_values(ascending=False)\n",
    "\n",
    "#Limiting the plot to the top 20 campaigns\n",
    "top_campaigns = sorted_avg_clicks_by_campaign.head(20)\n",
    "\n",
    "#Creating the bar plot \n",
    "top_campaigns.plot(kind = 'bar', color = 'skyblue', edgecolor = 'white')\n",
    "\n",
    "#Adding title, label and ticks to the plot\n",
    "plt.title('Average Clicks by Campaign (Top 20)')\n",
    "plt.xlabel('Campaign')\n",
    "plt.ylabel('Average Clicks')\n",
    "plt.xticks(rotation = 45, ha = \"right\")  \n",
    "\n",
    "#Showing the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of Data Visualizations: \n",
    "\n",
    "1. Histogram of Clicks:\n",
    "This Histogram helped us get an idea of the results are distributed in the train data. Seeing that the great majority of the references fell under 5 Clicks served as a benchmark for us to create the features that would end up going into the final model. Knowing that only few references had a large number of clicks directed our work towards better identifying those references with low number of clicks. Because the goal of the model was to achieve the lowest RMSE possible, taking this approach proved to be very effective. In addition not focusing so much on nailing the references with many Clicks ended up working in our favor when applying the model to the Kaggle data. \n",
    "\n",
    "2. Average Clicks per Impression Bin:\n",
    "This bar plot was essential for us when engineering features. At the beginning we weren't sure on what features would be good to incorporate to the model. Because impressions seemed to be all over the place in the data we weren't sure if this feature would be useful when modeling. When plotting the Impression bins against the Avg Clicks per Bin we noticed that the more impressions a reference had, the higher the amount of clicks. This finding was critical for us when developing the features that would form our final model.\n",
    "\n",
    "3. Average Clicks per Publisher:\n",
    "At the beginning of our work we really struggle to decide which features would better our model. From our analysis in R we already knew that not all publishers were made equal. But, being able to see that this also reflected in the train data was a big step for us. Google was the publisher with the most clicks, more specifically Google - Global. Being able to add this rational into the model definitely improved our final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><h3>Missing Value Analysis and Imputation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values in each column:\n",
      " Publisher Name            0\n",
      "Keyword                   0\n",
      "Match Type               44\n",
      "Campaign                  0\n",
      "Keyword Group             0\n",
      "Category                  0\n",
      "Bid Strategy           1193\n",
      "Status                    0\n",
      "Search Engine Bid         0\n",
      "Impressions               0\n",
      "Avg. Pos.                 0\n",
      "Avg. Cost per Click       0\n",
      "Clicks                    0\n",
      "set                       0\n",
      "dtype: int64\n",
      "\n",
      "Rows with missing values:\n",
      " Publisher Name\n",
      "Google - US        37\n",
      "Google - Global     7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Google US value count:\n",
      " Match Type\n",
      "Broad    1977\n",
      "Exact      19\n",
      "Name: count, dtype: int64 \n",
      "        \n",
      "Google Global value count:\n",
      " Match Type\n",
      "Broad    372\n",
      "Exact      2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "###Missing value analysis\n",
    "\n",
    "#Checking for missing values\n",
    "missing_summary = df_train.isnull().sum()\n",
    "\n",
    "###Analysing which publisher names had missing values (We thought maybe only google had some)\n",
    "\n",
    "#slicing the rows with missing values\n",
    "rows_with_missing_values = df_train[df_train['Match Type'].isnull()]\n",
    "\n",
    "#Checking which Publishers have missing values \n",
    "rows_with_missing_values = rows_with_missing_values['Publisher Name'].value_counts()\n",
    "\n",
    "###Doing analysis on the Match Type column to figure out how best to imputate the missing values\n",
    "\n",
    "#Separating the rows that have Publisher Name = to Google US\n",
    "google_us = df_train[df_train['Publisher Name'] == 'Google - US']\n",
    "\n",
    "#Seeing the different values inside the Match Type column and their count\n",
    "google_us_values = google_us['Match Type'].value_counts()\n",
    "\n",
    "#Separating the rows that have Publisher Name = to Google Global\n",
    "google_global = df_train[df_train['Publisher Name'] == 'Google - Global']\n",
    "\n",
    "#Seeing the different values inside the Match Type column and their count\n",
    "google_global_values = google_global['Match Type'].value_counts()\n",
    "\n",
    "#Printing results\n",
    "print(f\"\"\"\n",
    "Missing Values in each column:\\n {missing_summary}\n",
    "\n",
    "Rows with missing values:\\n {rows_with_missing_values}\n",
    "\n",
    "Google US value count:\\n {google_us_values} \n",
    "        \n",
    "Google Global value count:\\n {google_global_values}\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misssing values:\n",
      " Publisher Name         0\n",
      "Keyword                0\n",
      "Match Type             0\n",
      "Campaign               0\n",
      "Keyword Group          0\n",
      "Category               0\n",
      "Bid Strategy           0\n",
      "Status                 0\n",
      "Search Engine Bid      0\n",
      "Impressions            0\n",
      "Avg. Pos.              0\n",
      "Avg. Cost per Click    0\n",
      "Clicks                 0\n",
      "set                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "###Imputating missing values and replacing special characters\n",
    "\n",
    "#Chaning missing values in the Bid Strategy Column into no strategy\n",
    "df_full['Bid Strategy'].fillna('No Strategy', inplace = True)\n",
    "\n",
    "#Changing missing values in the Match Type column into broad\n",
    "df_full['Match Type'].fillna('Broad', inplace = True)\n",
    "\n",
    "#Checking for any other missing values in the data\n",
    "missing_sum = df_full.isnull().sum()\n",
    "\n",
    "print(f\"Misssing values:\\n {missing_sum}\")\n",
    "\n",
    "###Deleting special characters from the data \n",
    "\n",
    "#Deleting special characters in the Search Engine Bid column\n",
    "df_full['Search Engine Bid'] = df_full['Search Engine Bid'].astype(str).replace('\\$','', regex = True)\n",
    "\n",
    "#Deleting special characters in the Avg. Cost per Click column\n",
    "df_full['Avg. Cost per Click'] = df_full['Avg. Cost per Click'].astype(str).replace('\\$','', regex = True)\n",
    "\n",
    "#Deleting special characters in the Impressions column\n",
    "df_full['Impressions'] = df_full['Impressions'].astype(str).replace('\\,','', regex = True)\n",
    "\n",
    "#Deleting special characters in the Clicks column\n",
    "df_full['Clicks'] = df_full['Clicks'].astype(str).replace('\\,','', regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><h3>Transformations</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hp/ckxj948944zcmlndr0p65bwh0000gn/T/ipykernel_3594/1424162503.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_full['Bid Strategy'][df_full['Bid Strategy'] == 'No Strategy'] = 0\n"
     ]
    }
   ],
   "source": [
    "###Transforming categorical features into numbers\n",
    "\n",
    "#Encoding the Match Type column\n",
    "df_full['MatchType_encoded'] = le.fit_transform(df_full['Match Type']) \n",
    "\n",
    "#Encoding the Publisher Name column\n",
    "df_full['Publisher_encoded'] = le.fit_transform(df_full['Publisher Name'])\n",
    "\n",
    "#Encoding the Campaign column\n",
    "df_full['Campaign_encoded'] = le.fit_transform(df_full['Campaign']) \n",
    "\n",
    "#Changing 'No Strategy' values in the Bid Strategy column to 0\n",
    "df_full['Bid Strategy'][df_full['Bid Strategy'] == 'No Strategy'] = 0\n",
    "\n",
    "#Eliminating all non numerical data from the Bid Strategy column\n",
    "df_full['Bid Strategy'] = df_full['Bid Strategy'].astype(str).replace('[^\\d]+', '', regex=True)\n",
    "\n",
    "#Changing the Clicks column type first to numeric and then to interger\n",
    "df_full['Clicks'] = pd.to_numeric(df_full['Clicks'], errors = 'coerce')\n",
    "df_full['Clicks'] = df_full['Clicks'].astype('Int64')\n",
    "\n",
    "#Changing the Avg. Pos. column type first to numeric and then to interger\n",
    "df_full['Avg. Pos.'] = pd.to_numeric(df_full['Avg. Pos.'], errors = 'coerce')\n",
    "df_full['Avg. Pos.'] = df_full['Avg. Pos.'].astype('Float64')\n",
    "\n",
    "#Changing the Avg. Cost per Click column type first to numeric and then to interger\n",
    "df_full['Avg. Cost per Click'] = pd.to_numeric(df_full['Avg. Cost per Click'], errors = 'coerce')\n",
    "df_full['Avg. Cost per Click'] = df_full['Avg. Cost per Click'].astype('Float64')\n",
    "\n",
    "#Creating the log_Clicks column as the log of Clicks\n",
    "df_full['log_Clicks'] = np.log1p(df_full['Clicks'])\n",
    "\n",
    "df_full['Impressions'] = df_full['Impressions'].astype(int)\n",
    "df_full['Search Engine Bid'] = df_full['Search Engine Bid'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><h3>Feature Engineering</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Grouping the bid strategies into 4 categories:\n",
    "\n",
    "#Defining the conditions for each category\n",
    "condition_list = [\n",
    "                  df_full['Bid Strategy'] == '0',  # 0\n",
    "                  df_full['Bid Strategy'].isin(['12', '13', '14']),  # 3\n",
    "                  df_full['Bid Strategy'].isin(['25', '36']),  # 2\n",
    "                  df_full['Bid Strategy'] == '510'  # 1\n",
    "                 ]\n",
    "\n",
    "#Defining the labels for each category\n",
    "label_list = [0, 3, 2, 1]\n",
    "\n",
    "#Creating a new column called bid_strat_groups to divide the Impressions column into 4 categories\n",
    "df_full['bid_strat_groups'] = np.select(condition_list, label_list, default = np.nan)\n",
    "\n",
    "###Adding a feature to divide the values in the Impressions column by percentiles\n",
    "\n",
    "#Changing the impressions column type to interger\n",
    "df_full['Impressions'] = df_full['Impressions'].astype(int)\n",
    "\n",
    "#Creating bins to divide the values in the impressions column by percentile \n",
    "bins = df_full['Impressions'].quantile([0, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 1.0]).tolist()\n",
    "\n",
    "#Creating a list of labels to assign to each bin\n",
    "labels = [1, 2, 3, 4, 5, 6, 7, 8, 9 ,10] \n",
    "\n",
    "#Creating a new column with the Impressions data divided by bins\n",
    "df_full['impressions_groups'] = pd.cut(df_full['Impressions'], bins = bins, labels = labels, include_lowest = True)\n",
    "\n",
    "###Adding a feature to divide the values in the Avg. Pos. column by percentiles\n",
    "\n",
    "#Creating bins to divide the values in the Avg. Pos. column by percentile \n",
    "bins_1 = df_full['Avg. Pos.'].quantile([0, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 1.0]).tolist()\n",
    "\n",
    "#Creating a list of labels to assign to each bin\n",
    "labels_1 = [1, 2, 3, 4, 5, 6, 7, 8, 9 ,10] \n",
    "\n",
    "#Creating a new column with the Avg. Pos. data divided by bins\n",
    "df_full['avg_pos_groups'] = pd.cut(df_full['Avg. Pos.'], bins = bins_1, labels = labels_1, include_lowest = True)\n",
    "\n",
    "###Adding a feature to divide the values in the Avg. Cost per Click column by percentiles\n",
    "\n",
    "#Changing the Avg. Cost per Click column type to float\n",
    "df_full['Avg. Cost per Click'] = df_full['Avg. Cost per Click'].astype(float)\n",
    "\n",
    "#Creating bins to divide the values in the Avg. Pos. column by percentile \n",
    "bins_2 = df_full['Avg. Cost per Click'].quantile([0, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 1.0]).tolist()\n",
    "\n",
    "#Creating a list of labels to assign to each bin\n",
    "labels_2 = [1, 2, 3, 4, 5, 6, 7, 8, 9 ,10] \n",
    "\n",
    "#Creating a new column with the Avg. Pos. data divided by bins\n",
    "df_full['avg_cpc_groups'] = pd.cut(df_full['Avg. Cost per Click'], bins = bins_2, labels = labels_2, include_lowest = True)\n",
    "\n",
    "###Adding a feature to calculate the number of words in the Keyword column\n",
    "\n",
    "#Creating a feature that counts the number of words in the Keyword column\n",
    "df_full['Keyword Length'] = df_full['Keyword'].apply(lambda x: len(x.split()))\n",
    "\n",
    "###Changing the type of columns to numeric and then to interger\n",
    "\n",
    "#Creating a list of the columns that will be changed\n",
    "column_list = ['impressions_groups','avg_cpc_groups', 'avg_pos_groups']\n",
    "\n",
    "#For loop to convert the type of the columns\n",
    "for column in column_list:\n",
    "    #Converting the column to numeric\n",
    "    df_full[column] = pd.to_numeric(df_full[column], errors = 'coerce')\n",
    "    \n",
    "    #Converting the column to interger\n",
    "    df_full[column] = df_full[column].astype('int64')\n",
    "\n",
    "    \n",
    "###Last attempt at glory    \n",
    "\n",
    "#Creating features  that determine whether the publisher is google, msn, overture or yahoo\n",
    "df_full['Is_Google'] = df_full['Publisher Name'].str.contains('Google', case=False).astype(int)\n",
    "df_full['Is_Overture'] = df_full['Publisher Name'].str.contains('Overture', case=False).astype(int)\n",
    "df_full['Is_Yahoo'] = df_full['Publisher Name'].str.contains('Yahoo', case=False).astype(int)\n",
    "df_full['Is_MSN'] = df_full['Publisher Name'].str.contains('MSN', case=False).astype(int)\n",
    "\n",
    "\n",
    "#Creating features that determine whether the publisher is US or Global\n",
    "df_full['Is_US'] = df_full['Publisher Name'].str.contains('US', case=False).astype(int)\n",
    "df_full['Is_Global'] = df_full['Publisher Name'].str.contains('Global', case=False).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Critical things to know from exploratory data analysis, data preprocessing, and feature engineering:\n",
    "\n",
    "Exploratory data analysis showed that most features would have to be transformed for them to be utilized in the model. Many where categorical features that had to be encoded, and others where in types that had to be changed into numerical data. The most important original features were determined to be impressions, Publisher Name, Campaign and Search Engine Bid. From these features most of the other ones where engineered. We decided not to focus too much on the Keyword feature given that these keywords might be very different from the ones in the Kaggle data. Therefore, we only did a feature that calculated the number of words in the Keyword, given that this impacted the amount of Clicks and added value to the model. Regarding data processing, the missing values were easy to impute given that most could be imputed using the same value. Having to transform the type of the data and encoding categorical data was a recurring theme. The trickiest feature was Bid Strategy, where we had to first eliminate non numerical characters and then group the results in a ranking system. Most engineered features where derived groups from original features such as Impressions groups and avg_cpc_groups (cpc = cost per click). Finally, using log_Clicks proved to have better results than using just Clicks.\n",
    "\n",
    "In a last attempt at glory, we introduced 5 new features to categorize the publisher names in a better way. We dropped all the other features we created and uploaded the model in this manner, getting a better score. This was done at the very last moment before the submission, so we decided to leave or previous work, to showcase the big chunk of our work. Even though less, was more. Lesson learned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part III: Data Partitioning</h2><br>\n",
    "\n",
    "<br><h3>Separating the Kaggle Data</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parsing out testing data (needed for later) ##\n",
    "\n",
    "# dataset for kaggle\n",
    "kaggle_data = df_full[ df_full['set'] == 'Kaggle' ].copy()\n",
    "\n",
    "\n",
    "# dataset for model building\n",
    "df = df_full[ df_full['set'] == 'Not Kaggle' ].copy()\n",
    "df = df[df['Clicks'] < 1000000]\n",
    "\n",
    "# dropping set identifier (kaggle)\n",
    "kaggle_data.drop(labels = 'set',\n",
    "                 axis = 1,\n",
    "                 inplace = True)\n",
    "\n",
    "\n",
    "# dropping set identifier (model building)\n",
    "df.drop(labels = 'set',\n",
    "        axis = 1,\n",
    "        inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h3>Train-Test Split</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stablishing x features for the model\n",
    "x_features = ['MatchType_encoded', 'Publisher_encoded', 'Campaign_encoded', 'bid_strat_groups', 'impressions_groups', 'avg_pos_groups', 'avg_cpc_groups', 'Keyword Length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This were the features used in our last try\n",
    "x_features = ['Impressions', 'Search Engine Bid', 'Is_Google',\n",
    "       'Is_Overture', 'Is_Yahoo', 'Is_MSN', 'Is_US', 'Is_Global']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stablishing y variable for the model\n",
    "y_variable = 'Clicks' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Dataset Dimensions\n",
      "---------------------------\n",
      "Observations (Rows): 4410\n",
      "Features  (Columns): 28\n",
      "\n",
      "\n",
      "Training Data (X-side)\n",
      "----------------------\n",
      "Observations (Rows): 3528\n",
      "Features  (Columns): 8\n",
      "\n",
      "\n",
      "Training Data (y-side)\n",
      "----------------------\n",
      "Feature Name:        Clicks\n",
      "Observations (Rows): 3528\n",
      "\n",
      "\n",
      "Testing Data (X-side)\n",
      "---------------------\n",
      "Observations (Rows): 882\n",
      "Features  (Columns): 8\n",
      "\n",
      "\n",
      "Testing Data (y-side)\n",
      "---------------------\n",
      "Feature Name:        Clicks\n",
      "Observations (Rows): 882\n"
     ]
    }
   ],
   "source": [
    "#Prepping data for train-test split\n",
    "y_data = df[y_variable]\n",
    "\n",
    "\n",
    "#Removing non-numeric columns and missing values\n",
    "x_data = df[x_features].copy().select_dtypes(include=[int, float]).dropna(axis = 1)\n",
    "\n",
    "\n",
    "#Storing remaining x_features after the step above\n",
    "x_features = list(x_data.columns)\n",
    "\n",
    "\n",
    "#Train-test split (to validate the model)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, \n",
    "                                                    y_data, \n",
    "                                                    test_size    = 0.2,\n",
    "                                                    random_state = 7 )\n",
    "\n",
    "\n",
    "#Results of train-test split\n",
    "print(f\"\"\"\n",
    "Original Dataset Dimensions\n",
    "---------------------------\n",
    "Observations (Rows): {df.shape[0]}\n",
    "Features  (Columns): {df.shape[1]}\n",
    "\n",
    "\n",
    "Training Data (X-side)\n",
    "----------------------\n",
    "Observations (Rows): {x_train.shape[0]}\n",
    "Features  (Columns): {x_train.shape[1]}\n",
    "\n",
    "\n",
    "Training Data (y-side)\n",
    "----------------------\n",
    "Feature Name:        {y_train.name}\n",
    "Observations (Rows): {y_train.shape[0]}\n",
    "\n",
    "\n",
    "Testing Data (X-side)\n",
    "---------------------\n",
    "Observations (Rows): {x_test.shape[0]}\n",
    "Features  (Columns): {x_test.shape[1]}\n",
    "\n",
    "\n",
    "Testing Data (y-side)\n",
    "---------------------\n",
    "Feature Name:        {y_test.name}\n",
    "Observations (Rows): {y_test.shape[0]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best params used in the final model:\n",
    "\n",
    "random_search.best_params_ =  {'min_samples_split': 6, 'min_samples_leaf': 9, 'max_depth': 70, 'criterion': 'squared_error'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'min_samples_split': 6, 'min_samples_leaf': 9, 'max_depth': 70, 'criterion': 'squared_error'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter Tuning for Tree Model\n",
    "\n",
    "#Stablishing hyperparameter ranges\n",
    "param_grid = {\n",
    "    'criterion' : ['squared_error', 'friedman_mse'],\n",
    "    'max_depth': [5,10, 20, 30, 35, 40, 42, 43, 45, 50, 60, 70, 80, 90, 100], \n",
    "    'min_samples_split': np.arange(2, 10),\n",
    "    'min_samples_leaf': np.arange(2, 10)\n",
    "        }\n",
    "#Using RandomizedSearchCV to pick the best hyperparameters\n",
    "random_search = RandomizedSearchCV(estimator             = sklearn.tree.DecisionTreeRegressor(), \n",
    "                                   param_distributions   = param_grid, \n",
    "                                   cv                    = 3,          \n",
    "                                   n_iter                = 500,       \n",
    "                                   random_state          = 98)\n",
    "\n",
    "\n",
    "#Fitting the search to the data\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "print(f\"\"\"Best Parameters: {random_search.best_params_}\\n\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter Tuning for NeuralNet\n",
    "\n",
    "# Data scaling\n",
    "#scaler = StandardScaler()\n",
    "#x_train_scaled = scaler.fit_transform(x_train)\n",
    "#x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    " #Stablishing hyperparameter ranges\n",
    "param_grid = {\n",
    "        'hidden_layer_sizes': np.arange(10,40,1),\n",
    "        'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'alpha': np.arange(0.0001, 1, 0.05),\n",
    "        'solver': ['sgd', 'adam'],\n",
    "        'learning_rate': ['constant', 'adaptive','nvscaling']\n",
    "    }\n",
    "    \n",
    "# Using RandomizedSearchCV to pick the best hyperparameters\n",
    "random_search = RandomizedSearchCV(estimator=MLPRegressor(), \n",
    "                                   param_distributions=param_grid, \n",
    "                                   n_iter=500, \n",
    "                                   cv   =3,\n",
    "                                   random_state=98)\n",
    "\n",
    "#Fitting the search to the data\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "print(f\"\"\"Best Parameters: {random_search.best_params_}\\n\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part III: Candidate Modeling</h2><br>\n",
    "Develop your candidate models below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the model used for the final submission\n",
    "\n",
    "#Naming the model\n",
    "model_name = 'TREE' \n",
    "\n",
    "#Stablishing the model\n",
    "model = sklearn.tree.DecisionTreeRegressor(random_state = 98, **random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naming the model\n",
    "model_name = 'ElasticNet'\n",
    "\n",
    "#Stablishing the model\n",
    "model = SGDRegressor(random_state = 98, **random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naming the model\n",
    "model_name = 'NeuralNet'\n",
    "\n",
    "#Stablishing the model\n",
    "model = MLPRegressor(random_state = 98, **random_search.best_params_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.4758\n",
      "Test Score: -0.9532\n",
      "Train-Test Gap: 1.429\n",
      "Train RMSE: 814.4112\n",
      "Test RMSE: 673.3668\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model to the training data\n",
    "model_fit = model.fit(x_train, y_train)\n",
    "\n",
    "# Predicting on both training and new (test) data\n",
    "model_pred_train = model.predict(x_train)  # Predictions for the training set\n",
    "model_pred_test = model.predict(x_test)    # Predictions for the test set\n",
    "\n",
    "# Scoring the results\n",
    "model_train_score = model.score(x_train, y_train).round(4)\n",
    "model_test_score = model.score(x_test, y_test).round(4)\n",
    "model_gap = abs(model_train_score - model_test_score).round(4)\n",
    "\n",
    "# Calculating MSE for both training and testing predictions\n",
    "mse_train = mean_squared_error(y_train, model_pred_train)\n",
    "mse_test = mean_squared_error(y_test, model_pred_test)\n",
    "\n",
    "# Calculate the RMSE for both training and testing predictions\n",
    "rmse_train = np.sqrt(mse_train).round(4)\n",
    "rmse_test = np.sqrt(mse_test).round(4)\n",
    "\n",
    "# Optionally, print out the results\n",
    "print(f\"Train Score: {model_train_score}\")\n",
    "print(f\"Test Score: {model_test_score}\")\n",
    "print(f\"Train-Test Gap: {model_gap}\")\n",
    "print(f\"Train RMSE: {rmse_train}\")\n",
    "print(f\"Test RMSE: {rmse_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Candidate model development and final model selection:\n",
    "\n",
    "As a team we tried using KNN and DecisionTree given the familiarity we had with these models. Apart from that we tried to incorporate a Neural Network model, but the results we obtained ended up being worse than using DecisionTree or KNN. This was do to bad or lack of scaling, and because the features we engineered were not optimal to describe the data. After a lot of work we realized that the manner in which we grouped and categorized features such as Impressions and Publisher name, made the model worse instead of improving it. We noticed this when just using 'Impressions' and 'Search Engine Bid' gave us better RMSE scores. Because of this we decided to stick with DecisionTree, given that it showed the lower RMSE scores and the lowest gap between test and train. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>\n",
    "<h3>Residual Analysis</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entry_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mkt_2929</th>\n",
       "      <td>1</td>\n",
       "      <td>1.064516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mkt_4340</th>\n",
       "      <td>19</td>\n",
       "      <td>23.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mkt_4468</th>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mkt_3180</th>\n",
       "      <td>7</td>\n",
       "      <td>36.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mkt_4293</th>\n",
       "      <td>1</td>\n",
       "      <td>39.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mkt_1815</th>\n",
       "      <td>4</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mkt_1966</th>\n",
       "      <td>1</td>\n",
       "      <td>1.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mkt_3739</th>\n",
       "      <td>32</td>\n",
       "      <td>19.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mkt_3139</th>\n",
       "      <td>3</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mkt_200</th>\n",
       "      <td>4</td>\n",
       "      <td>69.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          True  Predicted\n",
       "entry_id                 \n",
       "mkt_2929     1   1.064516\n",
       "mkt_4340    19  23.888889\n",
       "mkt_4468     1  15.000000\n",
       "mkt_3180     7  36.900000\n",
       "mkt_4293     1  39.363636\n",
       "...        ...        ...\n",
       "mkt_1815     4   2.666667\n",
       "mkt_1966     1   1.823529\n",
       "mkt_3739    32  19.142857\n",
       "mkt_3139     3   2.000000\n",
       "mkt_200      4  69.400000\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Residual Analysis\n",
    "\n",
    "#y_test = np.expm1(y_test).round(0)\n",
    "#model_pred_test = np.expm1(model_pred_test).round(0)\n",
    "\n",
    "#Organizing residuals\n",
    "model_residuals = {\"True\"            : y_test,\n",
    "                   \"Predicted\"       : model_pred_test\n",
    "                  }\n",
    "\n",
    "\n",
    "#Converting residuals into df\n",
    "model_resid_df = pd.DataFrame(data = model_residuals)\n",
    "\n",
    "\n",
    "#Checking results\n",
    "model_resid_df.head(n = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part IV: Preparing Submission File for Kaggle</h2><br>\n",
    "The code below will store the predicted values for each of the models above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x-data\n",
    "x_data_kaggle = kaggle_data[x_features].copy()\n",
    "\n",
    "\n",
    "#y-data\n",
    "y_data_kaggle = kaggle_data[y_variable]\n",
    "\n",
    "#Activate if scaling data\n",
    "#x_data_kaggle = scaler.fit_transform(x_data_kaggle)\n",
    "\n",
    "\n",
    "#Fitting model from above to the Kaggle test data\n",
    "kaggle_predictions = model.predict(x_data_kaggle)\n",
    "\n",
    "#Activate if using log_rentals\n",
    "#kaggle_predictions = np.expm1(kaggle_predictions).round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>\n",
    "<h3>Creating the Kaggle File</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Kaggle Submission File\n",
    "\n",
    "#Organizing predictions\n",
    "model_predictions = {\"Clicks\" : kaggle_predictions}\n",
    "\n",
    "\n",
    "#Converting predictions into df\n",
    "model_pred_df = pd.DataFrame(data  = model_predictions,\n",
    "                             index = df_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naming the cvs file with the Kaggle results\n",
    "model_pred_df.to_csv(path_or_buf = \"./model_output/try16.csv\",\n",
    "                     index       = True,\n",
    "                     index_label = 'entry_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
